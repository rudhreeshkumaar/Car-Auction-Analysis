{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7Byi9UOpjEC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>TopThreeAmericanName</th>\n",
       "      <th>Make</th>\n",
       "      <th>RetailAVG</th>\n",
       "      <th>AuctionAVG</th>\n",
       "      <th>VehBCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTHER ASIAN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>KIA</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>7128.5</td>\n",
       "      <td>6100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>6948.0</td>\n",
       "      <td>5970.5</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>11199.0</td>\n",
       "      <td>8061.5</td>\n",
       "      <td>7500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD</td>\n",
       "      <td>6696.5</td>\n",
       "      <td>5737.5</td>\n",
       "      <td>4725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>7046.0</td>\n",
       "      <td>6061.0</td>\n",
       "      <td>5670.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nationality TopThreeAmericanName      Make  RetailAVG  AuctionAVG  VehBCost\n",
       "0  OTHER ASIAN                OTHER       KIA    10300.0      7128.5    6100.0\n",
       "1     AMERICAN             CHRYSLER     DODGE     6948.0      5970.5    4000.0\n",
       "2     AMERICAN             CHRYSLER     DODGE    11199.0      8061.5    7500.0\n",
       "3     AMERICAN                 FORD      FORD     6696.5      5737.5    4725.0\n",
       "4     AMERICAN             CHRYSLER  CHRYSLER     7046.0      6061.0    5670.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READ AND DROP COLUMNS\n",
    "df1 = pd.read_csv(\"D:/DM_Project_Dataset/training_cleaned.csv\")\n",
    "df = df1.loc[:, ['Nationality',\n",
    " 'TopThreeAmericanName',\n",
    " 'Make',\n",
    " 'RetailAVG',\n",
    " 'AuctionAVG',\n",
    " 'VehBCost']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation and Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Identify the string columns\n",
    "string_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Loop over each string column and encode it using a LabelEncoder\n",
    "for col in string_cols:\n",
    "    if col in df.columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_norm = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_norm\n",
    "y = df1['IsBadBuy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Lt2eYlXXpcID",
    "outputId": "5d52aa5e-8959-49d9-8a17-a0bece0af58c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for ----> recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.000 (+/-0.000) for {'learning_rate': 0.1, 'n_estimators': 5}\n",
      "0.000 (+/-0.000) for {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.000 (+/-0.000) for {'learning_rate': 0.1, 'n_estimators': 25}\n",
      "0.000 (+/-0.001) for {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.002 (+/-0.003) for {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.000 (+/-0.000) for {'learning_rate': 0.25, 'n_estimators': 5}\n",
      "0.000 (+/-0.000) for {'learning_rate': 0.25, 'n_estimators': 10}\n",
      "0.000 (+/-0.001) for {'learning_rate': 0.25, 'n_estimators': 25}\n",
      "0.002 (+/-0.003) for {'learning_rate': 0.25, 'n_estimators': 50}\n",
      "0.002 (+/-0.003) for {'learning_rate': 0.25, 'n_estimators': 100}\n",
      "0.000 (+/-0.000) for {'learning_rate': 0.5, 'n_estimators': 5}\n",
      "0.000 (+/-0.001) for {'learning_rate': 0.5, 'n_estimators': 10}\n",
      "0.002 (+/-0.003) for {'learning_rate': 0.5, 'n_estimators': 25}\n",
      "0.002 (+/-0.003) for {'learning_rate': 0.5, 'n_estimators': 50}\n",
      "0.002 (+/-0.003) for {'learning_rate': 0.5, 'n_estimators': 100}\n",
      "0.000 (+/-0.000) for {'learning_rate': 0.75, 'n_estimators': 5}\n",
      "0.000 (+/-0.001) for {'learning_rate': 0.75, 'n_estimators': 10}\n",
      "0.002 (+/-0.003) for {'learning_rate': 0.75, 'n_estimators': 25}\n",
      "0.002 (+/-0.003) for {'learning_rate': 0.75, 'n_estimators': 50}\n",
      "0.002 (+/-0.004) for {'learning_rate': 0.75, 'n_estimators': 100}\n",
      "0.000 (+/-0.000) for {'learning_rate': 1, 'n_estimators': 5}\n",
      "0.002 (+/-0.004) for {'learning_rate': 1, 'n_estimators': 10}\n",
      "0.003 (+/-0.006) for {'learning_rate': 1, 'n_estimators': 25}\n",
      "0.003 (+/-0.005) for {'learning_rate': 1, 'n_estimators': 50}\n",
      "0.003 (+/-0.005) for {'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     20294\n",
      "           1       0.60      0.00      0.01      2912\n",
      "\n",
      "    accuracy                           0.87     23206\n",
      "   macro avg       0.74      0.50      0.47     23206\n",
      "weighted avg       0.84      0.87      0.82     23206\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for ----> f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.467 (+/-0.000) for {'learning_rate': 0.1, 'n_estimators': 5}\n",
      "0.467 (+/-0.000) for {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.467 (+/-0.000) for {'learning_rate': 0.1, 'n_estimators': 25}\n",
      "0.468 (+/-0.001) for {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.469 (+/-0.003) for {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.467 (+/-0.000) for {'learning_rate': 0.25, 'n_estimators': 5}\n",
      "0.467 (+/-0.000) for {'learning_rate': 0.25, 'n_estimators': 10}\n",
      "0.468 (+/-0.001) for {'learning_rate': 0.25, 'n_estimators': 25}\n",
      "0.469 (+/-0.003) for {'learning_rate': 0.25, 'n_estimators': 50}\n",
      "0.469 (+/-0.003) for {'learning_rate': 0.25, 'n_estimators': 100}\n",
      "0.467 (+/-0.000) for {'learning_rate': 0.5, 'n_estimators': 5}\n",
      "0.468 (+/-0.001) for {'learning_rate': 0.5, 'n_estimators': 10}\n",
      "0.469 (+/-0.003) for {'learning_rate': 0.5, 'n_estimators': 25}\n",
      "0.469 (+/-0.003) for {'learning_rate': 0.5, 'n_estimators': 50}\n",
      "0.470 (+/-0.003) for {'learning_rate': 0.5, 'n_estimators': 100}\n",
      "0.467 (+/-0.000) for {'learning_rate': 0.75, 'n_estimators': 5}\n",
      "0.468 (+/-0.001) for {'learning_rate': 0.75, 'n_estimators': 10}\n",
      "0.470 (+/-0.003) for {'learning_rate': 0.75, 'n_estimators': 25}\n",
      "0.469 (+/-0.003) for {'learning_rate': 0.75, 'n_estimators': 50}\n",
      "0.470 (+/-0.004) for {'learning_rate': 0.75, 'n_estimators': 100}\n",
      "0.467 (+/-0.000) for {'learning_rate': 1, 'n_estimators': 5}\n",
      "0.469 (+/-0.004) for {'learning_rate': 1, 'n_estimators': 10}\n",
      "0.470 (+/-0.006) for {'learning_rate': 1, 'n_estimators': 25}\n",
      "0.470 (+/-0.005) for {'learning_rate': 1, 'n_estimators': 50}\n",
      "0.471 (+/-0.005) for {'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     20294\n",
      "           1       0.60      0.00      0.01      2912\n",
      "\n",
      "    accuracy                           0.87     23206\n",
      "   macro avg       0.74      0.50      0.47     23206\n",
      "weighted avg       0.84      0.87      0.82     23206\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = {\n",
    "    'n_estimators': [5, 10, 25, 50, 100],\n",
    "    'learning_rate' : [0.1, 0.25, 0.5, 0.75, 1],\n",
    " }\n",
    "\n",
    "#scores = ['precision', 'recall', 'f1']\n",
    "scores = ['recall', 'f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for ----> %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    obj = AdaBoostClassifier()\n",
    "    \n",
    "    if (score == \"recall\"):\n",
    "      clf = GridSearchCV(obj, tuned_parameters, cv=5, scoring=score)\n",
    "    else:\n",
    "      clf = GridSearchCV(obj, tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CV_AdaBoost.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
